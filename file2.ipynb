{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Id  OrgId  IncidentId  AlertId                 Timestamp  \\\n",
      "0   180388628218      0         612   123247  2024-06-04T06:05:15.000Z   \n",
      "1   455266534868     88         326   210035  2024-06-14T03:01:25.000Z   \n",
      "2  1056561957389    809       58352   712507  2024-06-13T04:52:55.000Z   \n",
      "3  1279900258736     92       32992   774301  2024-06-10T16:39:36.000Z   \n",
      "4   214748368522    148        4359   188041  2024-06-15T01:08:07.000Z   \n",
      "\n",
      "   DetectorId  AlertTitle           Category MitreTechniques   IncidentGrade  \\\n",
      "0           7           6      InitialAccess             NaN    TruePositive   \n",
      "1          58          43       Exfiltration             NaN   FalsePositive   \n",
      "2         423         298      InitialAccess           T1189   FalsePositive   \n",
      "3           2           2  CommandAndControl             NaN  BenignPositive   \n",
      "4           9          74          Execution             NaN    TruePositive   \n",
      "\n",
      "   ... ResourceType Roles OSFamily OSVersion  AntispamDirection  \\\n",
      "0  ...          NaN   NaN        5        66                NaN   \n",
      "1  ...          NaN   NaN        5        66                NaN   \n",
      "2  ...          NaN   NaN        5        66                NaN   \n",
      "3  ...          NaN   NaN        5        66                NaN   \n",
      "4  ...          NaN   NaN        5        66                NaN   \n",
      "\n",
      "   SuspicionLevel  LastVerdict  CountryCode  State   City  \n",
      "0             NaN          NaN           31      6      3  \n",
      "1             NaN          NaN          242   1445  10630  \n",
      "2      Suspicious   Suspicious          242   1445  10630  \n",
      "3      Suspicious   Suspicious          242   1445  10630  \n",
      "4             NaN          NaN          242   1445  10630  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Id         OrgId    IncidentId       AlertId    DetectorId  \\\n",
      "count  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06   \n",
      "mean   8.425494e+11  1.815800e+02  7.066349e+04  4.065188e+05  1.106724e+02   \n",
      "std    4.962499e+11  3.867784e+02  1.208369e+05  4.592827e+05  4.351038e+02   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    4.123169e+11  1.000000e+01  5.040000e+02  2.324200e+04  2.000000e+00   \n",
      "50%    8.418136e+11  4.500000e+01  1.033600e+04  2.166520e+05  9.000000e+00   \n",
      "75%    1.271310e+12  1.710000e+02  8.432900e+04  6.715770e+05  4.500000e+01   \n",
      "max    1.709397e+12  6.147000e+03  5.997060e+05  1.721456e+06  9.522000e+03   \n",
      "\n",
      "         AlertTitle      DeviceId        Sha256     IpAddress           Url  \\\n",
      "count  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06   \n",
      "mean   2.947315e+03  9.566476e+04  1.287191e+05  2.857506e+05  1.503317e+05   \n",
      "std    1.146150e+04  1.635288e+04  3.399208e+04  1.412240e+05  3.750795e+04   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    2.000000e+00  9.879900e+04  1.382680e+05  3.606060e+05  1.603960e+05   \n",
      "50%    1.100000e+01  9.879900e+04  1.382680e+05  3.606060e+05  1.603960e+05   \n",
      "75%    1.800000e+02  9.879900e+04  1.382680e+05  3.606060e+05  1.603960e+05   \n",
      "max    1.131740e+05  9.879900e+04  1.382680e+05  3.606060e+05  1.603960e+05   \n",
      "\n",
      "       ...  ApplicationName  OAuthApplicationId      FileName    FolderPath  \\\n",
      "count  ...     9.516837e+06        9.516837e+06  9.516837e+06  9.516837e+06   \n",
      "mean   ...     3.342790e+03        8.807955e+02  2.622621e+05  1.076172e+05   \n",
      "std    ...     5.103381e+02        1.291083e+01  8.152956e+04  3.220835e+04   \n",
      "min    ...     0.000000e+00        0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    ...     3.421000e+03        8.810000e+02  2.895730e+05  1.176680e+05   \n",
      "50%    ...     3.421000e+03        8.810000e+02  2.895730e+05  1.176680e+05   \n",
      "75%    ...     3.421000e+03        8.810000e+02  2.895730e+05  1.176680e+05   \n",
      "max    ...     3.421000e+03        8.810000e+02  2.895730e+05  1.176680e+05   \n",
      "\n",
      "       ResourceIdName      OSFamily     OSVersion   CountryCode         State  \\\n",
      "count    9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06   \n",
      "mean     3.583477e+03  4.898537e+00  6.465558e+01  2.236742e+02  1.351488e+03   \n",
      "std      9.020262e+01  7.035099e-01  9.314929e+00  6.279729e+01  3.509808e+02   \n",
      "min      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%      3.586000e+03  5.000000e+00  6.600000e+01  2.420000e+02  1.445000e+03   \n",
      "50%      3.586000e+03  5.000000e+00  6.600000e+01  2.420000e+02  1.445000e+03   \n",
      "75%      3.586000e+03  5.000000e+00  6.600000e+01  2.420000e+02  1.445000e+03   \n",
      "max      3.586000e+03  5.000000e+00  6.600000e+01  2.420000e+02  1.445000e+03   \n",
      "\n",
      "               City  \n",
      "count  9.516837e+06  \n",
      "mean   9.936183e+03  \n",
      "std    2.606812e+03  \n",
      "min    0.000000e+00  \n",
      "25%    1.063000e+04  \n",
      "50%    1.063000e+04  \n",
      "75%    1.063000e+04  \n",
      "max    1.063000e+04  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9516837 entries, 0 to 9516836\n",
      "Data columns (total 45 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   Id                  int64  \n",
      " 1   OrgId               int64  \n",
      " 2   IncidentId          int64  \n",
      " 3   AlertId             int64  \n",
      " 4   Timestamp           object \n",
      " 5   DetectorId          int64  \n",
      " 6   AlertTitle          int64  \n",
      " 7   Category            object \n",
      " 8   MitreTechniques     object \n",
      " 9   IncidentGrade       object \n",
      " 10  ActionGrouped       object \n",
      " 11  ActionGranular      object \n",
      " 12  EntityType          object \n",
      " 13  EvidenceRole        object \n",
      " 14  DeviceId            int64  \n",
      " 15  Sha256              int64  \n",
      " 16  IpAddress           int64  \n",
      " 17  Url                 int64  \n",
      " 18  AccountSid          int64  \n",
      " 19  AccountUpn          int64  \n",
      " 20  AccountObjectId     int64  \n",
      " 21  AccountName         int64  \n",
      " 22  DeviceName          int64  \n",
      " 23  NetworkMessageId    int64  \n",
      " 24  EmailClusterId      float64\n",
      " 25  RegistryKey         int64  \n",
      " 26  RegistryValueName   int64  \n",
      " 27  RegistryValueData   int64  \n",
      " 28  ApplicationId       int64  \n",
      " 29  ApplicationName     int64  \n",
      " 30  OAuthApplicationId  int64  \n",
      " 31  ThreatFamily        object \n",
      " 32  FileName            int64  \n",
      " 33  FolderPath          int64  \n",
      " 34  ResourceIdName      int64  \n",
      " 35  ResourceType        object \n",
      " 36  Roles               object \n",
      " 37  OSFamily            int64  \n",
      " 38  OSVersion           int64  \n",
      " 39  AntispamDirection   object \n",
      " 40  SuspicionLevel      object \n",
      " 41  LastVerdict         object \n",
      " 42  CountryCode         int64  \n",
      " 43  State               int64  \n",
      " 44  City                int64  \n",
      "dtypes: float64(1), int64(30), object(14)\n",
      "memory usage: 3.2+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check data types and missing values\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Exploration and Understanding\n",
    "def load_and_explore_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(df.info())\n",
    "    print(df.describe())\n",
    "    print(df['target'].value_counts(normalize=True))\n",
    "    \n",
    "    # Visualize target distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='target', data=df)\n",
    "    plt.title('Distribution of Target Variable')\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Create preprocessing pipelines\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Splitting and Stratification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "def split_data(df, target_column):\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model Selection and Training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_model(X_train, y_train, preprocessor):\n",
    "    # Use Random Forest as an example\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Model Evaluation and Tuning\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Interpretation\n",
    "def interpret_model(model, X):\n",
    "    feature_importance = model.named_steps['classifier'].feature_importances_\n",
    "    feature_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
    "    \n",
    "    importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
    "    importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='importance', y='feature', data=importance_df.head(20))\n",
    "    plt.title('Top 20 Feature Importances')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 and 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\mr\\appdata\\roaming\\python\\python311\\site-packages (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\mr\\appdata\\roaming\\python\\python311\\site-packages (from imbalanced-learn) (2.0.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\mr\\appdata\\roaming\\python\\python311\\site-packages (from imbalanced-learn) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\mr\\appdata\\roaming\\python\\python311\\site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\mr\\appdata\\roaming\\python\\python311\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mr\\appdata\\roaming\\python\\python311\\site-packages (from imbalanced-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'OrgId', 'IncidentId', 'AlertId', 'Timestamp', 'DetectorId',\n",
      "       'AlertTitle', 'Category', 'MitreTechniques', 'IncidentGrade',\n",
      "       'ActionGrouped', 'ActionGranular', 'EntityType', 'EvidenceRole',\n",
      "       'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn',\n",
      "       'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId',\n",
      "       'EmailClusterId', 'RegistryKey', 'RegistryValueName',\n",
      "       'RegistryValueData', 'ApplicationId', 'ApplicationName',\n",
      "       'OAuthApplicationId', 'ThreatFamily', 'FileName', 'FolderPath',\n",
      "       'ResourceIdName', 'ResourceType', 'Roles', 'OSFamily', 'OSVersion',\n",
      "       'AntispamDirection', 'SuspicionLevel', 'LastVerdict', 'CountryCode',\n",
      "       'State', 'City'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_data(file_path, target_column=None):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(df.info())\n",
    "    print(df.describe())\n",
    "    \n",
    "    if target_column and target_column in df.columns:\n",
    "        print(df[target_column].value_counts(normalize=True))\n",
    "        \n",
    "        # Visualize target distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(x=target_column, data=df)\n",
    "        plt.title('Distribution of Target Variable')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Column '{target_column}' not found in the dataset.\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Preprocessing\n",
    "def preprocess_data(df):\n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Create preprocessing pipelines\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    return preprocessor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Splitting and Stratification\n",
    "def split_data(df, target_column):\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model Selection and Training\n",
    "def train_model(X_train, y_train, preprocessor):\n",
    "    # Use Random Forest as an example\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Model Evaluation and Tuning\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Interpretation\n",
    "def interpret_model(model, X):\n",
    "    feature_importance = model.named_steps['classifier'].feature_importances_\n",
    "    feature_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
    "    \n",
    "    importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
    "    importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='importance', y='feature', data=importance_df.head(20))\n",
    "    plt.title('Top 20 Feature Importances')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Load and explore data\n",
    "#     df = load_and_explore_data('train.csv')\n",
    "    \n",
    "#     # Print column names\n",
    "#     print(\"\\nAvailable columns in the dataset:\")\n",
    "#     for i, col in enumerate(df.columns):\n",
    "#         print(f\"{i}: {col}\")\n",
    "    \n",
    "#     # Ask user to input the index of the target column\n",
    "#     target_column_index = int(input(\"\\nPlease enter the index number of the target column (triage grade): \"))\n",
    "#     target_column = df.columns[target_column_index]\n",
    "    \n",
    "#     print(f\"Selected target column: {target_column}\")\n",
    "    \n",
    "#     # Load and explore data with the specified target column\n",
    "#     df = load_and_explore_data('train.csv', target_column=target_column)\n",
    "    \n",
    "#     # Preprocess data\n",
    "#     preprocessor = preprocess_data(df)\n",
    "    \n",
    "#     # Split data\n",
    "#     X_train, X_test, y_train, y_test = split_data(df, target_column)\n",
    "    \n",
    "#     # Train model\n",
    "#     model = train_model(X_train, y_train, preprocessor)\n",
    "    \n",
    "#     # Evaluate model\n",
    "#     evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "#     # Interpret model\n",
    "#     interpret_model(model, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Main execution\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Load and explore data without specifying target column\n",
    "#     df = load_and_explore_data('train.csv')\n",
    "    \n",
    "#     # Print column names\n",
    "#     print(\"\\nAvailable columns in the dataset:\")\n",
    "#     for i, col in enumerate(df.columns):\n",
    "#         print(f\"{i}: {col}\")\n",
    "    \n",
    "#     # Ask user to input the index of the target column\n",
    "#     target_column_index = int(input(\"\\nPlease enter the index number of the target column (triage grade): \"))\n",
    "#     target_column = df.columns[target_column_index]\n",
    "    \n",
    "#     print(f\"Selected target column: {target_column}\")\n",
    "    \n",
    "#     # Now proceed with the analysis using the selected target column\n",
    "#     df = load_and_explore_data('train.csv', target_column=target_column)\n",
    "    \n",
    "#     # Preprocess data\n",
    "#     preprocessor = preprocess_data(df)\n",
    "    \n",
    "#     # Split data\n",
    "#     X_train, X_test, y_train, y_test = split_data(df, target_column)\n",
    "    \n",
    "#     # Train model\n",
    "#     model = train_model(X_train, y_train, preprocessor)\n",
    "    \n",
    "#     # Evaluate model\n",
    "#     evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "#     # Interpret model\n",
    "#     interpret_model(model, X_train)\n",
    "    \n",
    "#     # Final evaluation on test set\n",
    "#     test_df = pd.read_csv('test.csv')\n",
    "#     if target_column in test_df.columns:\n",
    "#         X_test_final = test_df.drop(target_column, axis=1)\n",
    "#         y_test_final = test_df[target_column]\n",
    "        \n",
    "#         print(\"Final Test Set Evaluation:\")\n",
    "#         evaluate_model(model, X_test_final, y_test_final)\n",
    "#     else:\n",
    "#         print(f\"Target column '{target_column}' not found in test set. Unable to perform final evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Final Evaluation on Test Set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def final_evaluation_on_test_set(model, test_df, target_column):\n",
    "    # Check if target column exists in test set\n",
    "    if target_column in test_df.columns:\n",
    "        # Prepare test data\n",
    "        X_test_final = test_df.drop(target_column, axis=1)\n",
    "        y_test_final = test_df[target_column]\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_final = model.predict(X_test_final)\n",
    "        \n",
    "        # Compute metrics\n",
    "        f1 = f1_score(y_test_final, y_pred_final, average='macro')\n",
    "        precision = precision_score(y_test_final, y_pred_final, average='macro')\n",
    "        recall = recall_score(y_test_final, y_pred_final, average='macro')\n",
    "        \n",
    "        print(f\"Final Test Set Evaluation:\")\n",
    "        print(f\"Macro-F1 Score: {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        \n",
    "        # Detailed classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test_final, y_pred_final))\n",
    "        \n",
    "        return f1, precision, recall\n",
    "    else:\n",
    "        print(f\"Target column '{target_column}' not found in test set. Unable to perform final evaluation.\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model Evaluation\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "def evaluate_baseline_model(X_train, y_train, X_test, y_test):\n",
    "    # Define a baseline model\n",
    "    baseline_model = DummyClassifier(strategy='most_frequent')\n",
    "    \n",
    "    # Train the baseline model\n",
    "    baseline_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_baseline = baseline_model.predict(X_test)\n",
    "    \n",
    "    # Compute metrics\n",
    "    baseline_f1 = f1_score(y_test, y_pred_baseline, average='macro')\n",
    "    baseline_precision = precision_score(y_test, y_pred_baseline, average='macro')\n",
    "    baseline_recall = recall_score(y_test, y_pred_baseline, average='macro')\n",
    "    \n",
    "    print(\"Baseline Model Evaluation:\")\n",
    "    print(f\"Macro-F1 Score: {baseline_f1:.4f}\")\n",
    "    print(f\"Precision: {baseline_precision:.4f}\")\n",
    "    print(f\"Recall: {baseline_recall:.4f}\")\n",
    "    \n",
    "    return baseline_f1, baseline_precision, baseline_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9516837 entries, 0 to 9516836\n",
      "Data columns (total 45 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   Id                  int64  \n",
      " 1   OrgId               int64  \n",
      " 2   IncidentId          int64  \n",
      " 3   AlertId             int64  \n",
      " 4   Timestamp           object \n",
      " 5   DetectorId          int64  \n",
      " 6   AlertTitle          int64  \n",
      " 7   Category            object \n",
      " 8   MitreTechniques     object \n",
      " 9   IncidentGrade       object \n",
      " 10  ActionGrouped       object \n",
      " 11  ActionGranular      object \n",
      " 12  EntityType          object \n",
      " 13  EvidenceRole        object \n",
      " 14  DeviceId            int64  \n",
      " 15  Sha256              int64  \n",
      " 16  IpAddress           int64  \n",
      " 17  Url                 int64  \n",
      " 18  AccountSid          int64  \n",
      " 19  AccountUpn          int64  \n",
      " 20  AccountObjectId     int64  \n",
      " 21  AccountName         int64  \n",
      " 22  DeviceName          int64  \n",
      " 23  NetworkMessageId    int64  \n",
      " 24  EmailClusterId      float64\n",
      " 25  RegistryKey         int64  \n",
      " 26  RegistryValueName   int64  \n",
      " 27  RegistryValueData   int64  \n",
      " 28  ApplicationId       int64  \n",
      " 29  ApplicationName     int64  \n",
      " 30  OAuthApplicationId  int64  \n",
      " 31  ThreatFamily        object \n",
      " 32  FileName            int64  \n",
      " 33  FolderPath          int64  \n",
      " 34  ResourceIdName      int64  \n",
      " 35  ResourceType        object \n",
      " 36  Roles               object \n",
      " 37  OSFamily            int64  \n",
      " 38  OSVersion           int64  \n",
      " 39  AntispamDirection   object \n",
      " 40  SuspicionLevel      object \n",
      " 41  LastVerdict         object \n",
      " 42  CountryCode         int64  \n",
      " 43  State               int64  \n",
      " 44  City                int64  \n",
      "dtypes: float64(1), int64(30), object(14)\n",
      "memory usage: 3.2+ GB\n",
      "None\n",
      "                 Id         OrgId    IncidentId       AlertId    DetectorId  \\\n",
      "count  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06   \n",
      "mean   8.425494e+11  1.815800e+02  7.066349e+04  4.065188e+05  1.106724e+02   \n",
      "std    4.962499e+11  3.867784e+02  1.208369e+05  4.592827e+05  4.351038e+02   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    4.123169e+11  1.000000e+01  5.040000e+02  2.324200e+04  2.000000e+00   \n",
      "50%    8.418136e+11  4.500000e+01  1.033600e+04  2.166520e+05  9.000000e+00   \n",
      "75%    1.271310e+12  1.710000e+02  8.432900e+04  6.715770e+05  4.500000e+01   \n",
      "max    1.709397e+12  6.147000e+03  5.997060e+05  1.721456e+06  9.522000e+03   \n",
      "\n",
      "         AlertTitle      DeviceId        Sha256     IpAddress           Url  \\\n",
      "count  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06   \n",
      "mean   2.947315e+03  9.566476e+04  1.287191e+05  2.857506e+05  1.503317e+05   \n",
      "std    1.146150e+04  1.635288e+04  3.399208e+04  1.412240e+05  3.750795e+04   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    2.000000e+00  9.879900e+04  1.382680e+05  3.606060e+05  1.603960e+05   \n",
      "50%    1.100000e+01  9.879900e+04  1.382680e+05  3.606060e+05  1.603960e+05   \n",
      "75%    1.800000e+02  9.879900e+04  1.382680e+05  3.606060e+05  1.603960e+05   \n",
      "max    1.131740e+05  9.879900e+04  1.382680e+05  3.606060e+05  1.603960e+05   \n",
      "\n",
      "       ...  ApplicationName  OAuthApplicationId      FileName    FolderPath  \\\n",
      "count  ...     9.516837e+06        9.516837e+06  9.516837e+06  9.516837e+06   \n",
      "mean   ...     3.342790e+03        8.807955e+02  2.622621e+05  1.076172e+05   \n",
      "std    ...     5.103381e+02        1.291083e+01  8.152956e+04  3.220835e+04   \n",
      "min    ...     0.000000e+00        0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    ...     3.421000e+03        8.810000e+02  2.895730e+05  1.176680e+05   \n",
      "50%    ...     3.421000e+03        8.810000e+02  2.895730e+05  1.176680e+05   \n",
      "75%    ...     3.421000e+03        8.810000e+02  2.895730e+05  1.176680e+05   \n",
      "max    ...     3.421000e+03        8.810000e+02  2.895730e+05  1.176680e+05   \n",
      "\n",
      "       ResourceIdName      OSFamily     OSVersion   CountryCode         State  \\\n",
      "count    9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06   \n",
      "mean     3.583477e+03  4.898537e+00  6.465558e+01  2.236742e+02  1.351488e+03   \n",
      "std      9.020262e+01  7.035099e-01  9.314929e+00  6.279729e+01  3.509808e+02   \n",
      "min      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%      3.586000e+03  5.000000e+00  6.600000e+01  2.420000e+02  1.445000e+03   \n",
      "50%      3.586000e+03  5.000000e+00  6.600000e+01  2.420000e+02  1.445000e+03   \n",
      "75%      3.586000e+03  5.000000e+00  6.600000e+01  2.420000e+02  1.445000e+03   \n",
      "max      3.586000e+03  5.000000e+00  6.600000e+01  2.420000e+02  1.445000e+03   \n",
      "\n",
      "               City  \n",
      "count  9.516837e+06  \n",
      "mean   9.936183e+03  \n",
      "std    2.606812e+03  \n",
      "min    0.000000e+00  \n",
      "25%    1.063000e+04  \n",
      "50%    1.063000e+04  \n",
      "75%    1.063000e+04  \n",
      "max    1.063000e+04  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "Column 'None' not found in the dataset.\n",
      "\n",
      "Available columns in the dataset:\n",
      "0: Id\n",
      "1: OrgId\n",
      "2: IncidentId\n",
      "3: AlertId\n",
      "4: Timestamp\n",
      "5: DetectorId\n",
      "6: AlertTitle\n",
      "7: Category\n",
      "8: MitreTechniques\n",
      "9: IncidentGrade\n",
      "10: ActionGrouped\n",
      "11: ActionGranular\n",
      "12: EntityType\n",
      "13: EvidenceRole\n",
      "14: DeviceId\n",
      "15: Sha256\n",
      "16: IpAddress\n",
      "17: Url\n",
      "18: AccountSid\n",
      "19: AccountUpn\n",
      "20: AccountObjectId\n",
      "21: AccountName\n",
      "22: DeviceName\n",
      "23: NetworkMessageId\n",
      "24: EmailClusterId\n",
      "25: RegistryKey\n",
      "26: RegistryValueName\n",
      "27: RegistryValueData\n",
      "28: ApplicationId\n",
      "29: ApplicationName\n",
      "30: OAuthApplicationId\n",
      "31: ThreatFamily\n",
      "32: FileName\n",
      "33: FolderPath\n",
      "34: ResourceIdName\n",
      "35: ResourceType\n",
      "36: Roles\n",
      "37: OSFamily\n",
      "38: OSVersion\n",
      "39: AntispamDirection\n",
      "40: SuspicionLevel\n",
      "41: LastVerdict\n",
      "42: CountryCode\n",
      "43: State\n",
      "44: City\n",
      "Selected target column: IncidentId\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9516837 entries, 0 to 9516836\n",
      "Data columns (total 45 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   Id                  int64  \n",
      " 1   OrgId               int64  \n",
      " 2   IncidentId          int64  \n",
      " 3   AlertId             int64  \n",
      " 4   Timestamp           object \n",
      " 5   DetectorId          int64  \n",
      " 6   AlertTitle          int64  \n",
      " 7   Category            object \n",
      " 8   MitreTechniques     object \n",
      " 9   IncidentGrade       object \n",
      " 10  ActionGrouped       object \n",
      " 11  ActionGranular      object \n",
      " 12  EntityType          object \n",
      " 13  EvidenceRole        object \n",
      " 14  DeviceId            int64  \n",
      " 15  Sha256              int64  \n",
      " 16  IpAddress           int64  \n",
      " 17  Url                 int64  \n",
      " 18  AccountSid          int64  \n",
      " 19  AccountUpn          int64  \n",
      " 20  AccountObjectId     int64  \n",
      " 21  AccountName         int64  \n",
      " 22  DeviceName          int64  \n",
      " 23  NetworkMessageId    int64  \n",
      " 24  EmailClusterId      float64\n",
      " 25  RegistryKey         int64  \n",
      " 26  RegistryValueName   int64  \n",
      " 27  RegistryValueData   int64  \n",
      " 28  ApplicationId       int64  \n",
      " 29  ApplicationName     int64  \n",
      " 30  OAuthApplicationId  int64  \n",
      " 31  ThreatFamily        object \n",
      " 32  FileName            int64  \n",
      " 33  FolderPath          int64  \n",
      " 34  ResourceIdName      int64  \n",
      " 35  ResourceType        object \n",
      " 36  Roles               object \n",
      " 37  OSFamily            int64  \n",
      " 38  OSVersion           int64  \n",
      " 39  AntispamDirection   object \n",
      " 40  SuspicionLevel      object \n",
      " 41  LastVerdict         object \n",
      " 42  CountryCode         int64  \n",
      " 43  State               int64  \n",
      " 44  City                int64  \n",
      "dtypes: float64(1), int64(30), object(14)\n",
      "memory usage: 3.2+ GB\n",
      "None\n",
      "                 Id         OrgId    IncidentId       AlertId    DetectorId  \\\n",
      "count  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06   \n",
      "mean   8.425494e+11  1.815800e+02  7.066349e+04  4.065188e+05  1.106724e+02   \n",
      "std    4.962499e+11  3.867784e+02  1.208369e+05  4.592827e+05  4.351038e+02   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    4.123169e+11  1.000000e+01  5.040000e+02  2.324200e+04  2.000000e+00   \n",
      "50%    8.418136e+11  4.500000e+01  1.033600e+04  2.166520e+05  9.000000e+00   \n",
      "75%    1.271310e+12  1.710000e+02  8.432900e+04  6.715770e+05  4.500000e+01   \n",
      "max    1.709397e+12  6.147000e+03  5.997060e+05  1.721456e+06  9.522000e+03   \n",
      "\n",
      "         AlertTitle      DeviceId        Sha256     IpAddress           Url  \\\n",
      "count  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06   \n",
      "mean   2.947315e+03  9.566476e+04  1.287191e+05  2.857506e+05  1.503317e+05   \n",
      "std    1.146150e+04  1.635288e+04  3.399208e+04  1.412240e+05  3.750795e+04   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    2.000000e+00  9.879900e+04  1.382680e+05  3.606060e+05  1.603960e+05   \n",
      "50%    1.100000e+01  9.879900e+04  1.382680e+05  3.606060e+05  1.603960e+05   \n",
      "75%    1.800000e+02  9.879900e+04  1.382680e+05  3.606060e+05  1.603960e+05   \n",
      "max    1.131740e+05  9.879900e+04  1.382680e+05  3.606060e+05  1.603960e+05   \n",
      "\n",
      "       ...  ApplicationName  OAuthApplicationId      FileName    FolderPath  \\\n",
      "count  ...     9.516837e+06        9.516837e+06  9.516837e+06  9.516837e+06   \n",
      "mean   ...     3.342790e+03        8.807955e+02  2.622621e+05  1.076172e+05   \n",
      "std    ...     5.103381e+02        1.291083e+01  8.152956e+04  3.220835e+04   \n",
      "min    ...     0.000000e+00        0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    ...     3.421000e+03        8.810000e+02  2.895730e+05  1.176680e+05   \n",
      "50%    ...     3.421000e+03        8.810000e+02  2.895730e+05  1.176680e+05   \n",
      "75%    ...     3.421000e+03        8.810000e+02  2.895730e+05  1.176680e+05   \n",
      "max    ...     3.421000e+03        8.810000e+02  2.895730e+05  1.176680e+05   \n",
      "\n",
      "       ResourceIdName      OSFamily     OSVersion   CountryCode         State  \\\n",
      "count    9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06  9.516837e+06   \n",
      "mean     3.583477e+03  4.898537e+00  6.465558e+01  2.236742e+02  1.351488e+03   \n",
      "std      9.020262e+01  7.035099e-01  9.314929e+00  6.279729e+01  3.509808e+02   \n",
      "min      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%      3.586000e+03  5.000000e+00  6.600000e+01  2.420000e+02  1.445000e+03   \n",
      "50%      3.586000e+03  5.000000e+00  6.600000e+01  2.420000e+02  1.445000e+03   \n",
      "75%      3.586000e+03  5.000000e+00  6.600000e+01  2.420000e+02  1.445000e+03   \n",
      "max      3.586000e+03  5.000000e+00  6.600000e+01  2.420000e+02  1.445000e+03   \n",
      "\n",
      "               City  \n",
      "count  9.516837e+06  \n",
      "mean   9.936183e+03  \n",
      "std    2.606812e+03  \n",
      "min    0.000000e+00  \n",
      "25%    1.063000e+04  \n",
      "50%    1.063000e+04  \n",
      "75%    1.063000e+04  \n",
      "max    1.063000e+04  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "IncidentId\n",
      "0         3.151993e-03\n",
      "2         2.156704e-03\n",
      "7         1.287403e-03\n",
      "9         1.224777e-03\n",
      "14        1.074727e-03\n",
      "              ...     \n",
      "272487    1.050769e-07\n",
      "591046    1.050769e-07\n",
      "586536    1.050769e-07\n",
      "231047    1.050769e-07\n",
      "591744    1.050769e-07\n",
      "Name: proportion, Length: 466151, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and explore data\n",
    "    df = load_and_explore_data('train.csv')\n",
    "\n",
    "    # Print column names\n",
    "    print(\"\\nAvailable columns in the dataset:\")\n",
    "    for i, col in enumerate(df.columns):\n",
    "        print(f\"{i}: {col}\")\n",
    "\n",
    "    # Ask user to input the index of the target column\n",
    "    target_column_index = int(input(\"\\nPlease enter the index number of the target column: \"))\n",
    "    target_column = df.columns[target_column_index]\n",
    "\n",
    "    print(f\"Selected target column: {target_column}\")\n",
    "\n",
    "    # Load and explore data with the specified target column\n",
    "    df = load_and_explore_data('train.csv', target_column=target_column)\n",
    "\n",
    "    # Preprocess data\n",
    "    preprocessor = preprocess_data(df)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df, target_column)\n",
    "\n",
    "    # Train model\n",
    "    model = train_model(X_train, y_train, preprocessor)\n",
    "\n",
    "    # Evaluate model\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "\n",
    "    # Interpret model\n",
    "    interpret_model(model, X_train)\n",
    "\n",
    "    # Evaluate baseline model\n",
    "    baseline_f1, baseline_precision, baseline_recall = evaluate_baseline_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    final_evaluation_on_test_set(model, test_df, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('train.csv')\n",
    "# print(df.head())  # Check the first few rows to confirm correct loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
